<!DOCTYPE html>
<html>
<head>
  <title>Face Anatomy Pro - Tracking Test</title>
  <style>
    body { margin: 0; background: #1a1a1a; color: white; font-family: 'Segoe UI', sans-serif; overflow: hidden; }
    #container { position: relative; width: 100vw; height: 100vh; display: flex; justify-content: center; align-items: center; }
    video, canvas { position: absolute; transform: scaleX(-1); border-radius: 10px; }
    .status-bar { position: fixed; top: 20px; z-index: 100; background: rgba(0,0,0,0.6); padding: 10px 20px; border-radius: 30px; border: 1px solid #00ffcc; box-shadow: 0 0 15px #00ffcc55; }
  </style>
</head>
<body>
  <div class="status-bar">Система: <span id="status">Ініціалізація AI...</span></div>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="output_canvas"></canvas>
  </div>

  <script type="module">
    import { FaceLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const video = document.getElementById("video");
    const canvas = document.getElementById("output_canvas");
    const canvasCtx = canvas.getContext("2d");
    const statusElement = document.getElementById("status");

    let faceLandmarker;
    let lastVideoTime = -1;

    async function setupAI() {
        const filesetResolver = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
            baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`, delegate: "GPU" },
            outputFaceBlendshapes: true,
            runningMode: "VIDEO",
            numFaces: 1
        });
        statusElement.innerText = "AI готовий. Запуск камери...";
        startCamera();
    }

    async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 1280, height: 720 } });
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
    }

    async function predictWebcam() {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            const results = faceLandmarker.detectForVideo(video, performance.now());

            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            const drawingUtils = new DrawingUtils(canvasCtx);

            if (results.faceLandmarks) {
                for (const landmarks of results.faceLandmarks) {
                    drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_TESSELATION, { color: "#C0C0C070", lineWidth: 1 });
                    drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, { color: "#FF3030" });
                    drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, { color: "#30FF30" });
                    statusElement.innerText = "Аналіз міміки активний ✅";
                }
            }
        }
        window.requestAnimationFrame(predictWebcam);
    }

    setupAI();
  </script>
</body>
</html>
